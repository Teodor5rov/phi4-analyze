{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0b6dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to analyze file: outputs/analysis_Phi-4-reasoning-plus_20250617_235420.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Configuration ---\n",
    "# Set the style for our plots to make them look nice\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (18, 8)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "\n",
    "# Define the path to your analysis file\n",
    "# The filename is the one you provided.\n",
    "file_path = \"outputs/analysis_Phi-4-reasoning-plus_20250617_235420.json\"\n",
    "\n",
    "print(f\"Ready to analyze file: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602ff3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully!\n",
      "Total number of generated tokens: 32768\n",
      "\n",
      "Data Head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>chosen_token</th>\n",
       "      <th>chosen_token_prob</th>\n",
       "      <th>top_k_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;think&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'token': '&lt;think&gt;', 'probability': 1.0}, {'t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>We</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'token': 'We', 'probability': 1.0}, {'token'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>are</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'token': ' are', 'probability': 1.0}, {'toke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>given</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>[{'token': ' given', 'probability': 0.70703125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>0.816406</td>\n",
       "      <td>[{'token': ' a', 'probability': 0.81640625}, {...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step chosen_token  chosen_token_prob  \\\n",
       "0     1      <think>           1.000000   \n",
       "1     2           We           1.000000   \n",
       "2     3          are           1.000000   \n",
       "3     4        given           0.707031   \n",
       "4     5            a           0.816406   \n",
       "\n",
       "                                   top_k_predictions  \n",
       "0  [{'token': '<think>', 'probability': 1.0}, {'t...  \n",
       "1  [{'token': 'We', 'probability': 1.0}, {'token'...  \n",
       "2  [{'token': ' are', 'probability': 1.0}, {'toke...  \n",
       "3  [{'token': ' given', 'probability': 0.70703125...  \n",
       "4  [{'token': ' a', 'probability': 0.81640625}, {...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32768 entries, 0 to 32767\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   step               32768 non-null  int64  \n",
      " 1   chosen_token       32768 non-null  object \n",
      " 2   chosen_token_prob  32768 non-null  float64\n",
      " 3   top_k_predictions  32768 non-null  object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON data into a pandas DataFrame for easy manipulation\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Convert the list of dictionaries directly into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"File loaded successfully!\")\n",
    "    print(f\"Total number of generated tokens: {len(df)}\")\n",
    "    \n",
    "    # Display the first few rows to verify the structure\n",
    "    print(\"\\nData Head:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # Display summary information about the DataFrame\n",
    "    print(\"\\nData Info:\")\n",
    "    df.info()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file was not found at {file_path}\")\n",
    "    print(\"Please make sure the filename and path are correct.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f16c05",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'variance'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teo\\Desktop\\phi4-analyzer\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'variance'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m plt.figure()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Create a line plot of the variance\u001b[39;00m\n\u001b[32m      7\u001b[39m lineplot = sns.lineplot(\n\u001b[32m      8\u001b[39m     x=df.index, \n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     y=\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvariance\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \n\u001b[32m     10\u001b[39m     label=\u001b[33m'\u001b[39m\u001b[33mToken Probability Variance\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m     linewidth=\u001b[32m2\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# --- Optional: Use a logarithmic scale if variance values are very spiky ---\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# If your peaks are extremely high and valleys are very low, a log scale can help.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Uncomment the line below to try it.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# plt.yscale('log')\u001b[39;00m\n\u001b[32m     19\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mModel Confidence (Variance) at Each Generation Step\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m16\u001b[39m, weight=\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teo\\Desktop\\phi4-analyzer\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\teo\\Desktop\\phi4-analyzer\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'variance'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, let's create the main plot to visualize the variance at each step.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    plt.figure()\n",
    "    \n",
    "    # Create a line plot of the variance\n",
    "    lineplot = sns.lineplot(\n",
    "        x=df.index, \n",
    "        y=df['variance'], \n",
    "        label='Token Probability Variance',\n",
    "        linewidth=2\n",
    "    )\n",
    "    \n",
    "    # --- Optional: Use a logarithmic scale if variance values are very spiky ---\n",
    "    # If your peaks are extremely high and valleys are very low, a log scale can help.\n",
    "    # Uncomment the line below to try it.\n",
    "    # plt.yscale('log')\n",
    "\n",
    "    plt.title('Model Confidence (Variance) at Each Generation Step', fontsize=16, weight='bold')\n",
    "    plt.xlabel('Generation Step (Token Number)', fontsize=12)\n",
    "    plt.ylabel('Variance of Probability Distribution', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"DataFrame 'df' not available. Please run the previous cell successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b06017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 5 steps where the model was most confident.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    # We select the relevant columns for a clean view\n",
    "    columns_to_show = ['step', 'chosen_token', 'variance', 'chosen_token_prob']\n",
    "    \n",
    "    highest_variance_tokens = df.nlargest(5, 'variance')[columns_to_show]\n",
    "    \n",
    "    print(\"Top 5 Most Confident Steps (Highest Variance):\")\n",
    "    display(highest_variance_tokens)\n",
    "else:\n",
    "    print(\"DataFrame 'df' not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 5 steps where the model was most uncertain.\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    # We select the same columns for a clean view\n",
    "    columns_to_show = ['step', 'chosen_token', 'variance', 'chosen_token_prob']\n",
    "    \n",
    "    lowest_variance_tokens = df.nsmallest(5, 'variance')[columns_to_show]\n",
    "    \n",
    "    print(\"Top 5 Most Uncertain Steps (Lowest Variance):\")\n",
    "    display(lowest_variance_tokens)\n",
    "else:\n",
    "    print(\"DataFrame 'df' not available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
